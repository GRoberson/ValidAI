#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üé≠ ValidAI RAG Multimodal - Sistema RAG com Suporte Multimodal

Sistema RAG avan√ßado que suporta documentos, imagens, v√≠deos e outros
tipos de m√≠dia usando Vertex AI multimodal e Gemini Vision.
"""

import os
import uuid
import json
import base64
import logging
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
from datetime import datetime
import mimetypes

# Google Cloud imports
from google import genai
from google.cloud import storage
from google.genai.types import GenerateContentConfig, Retrieval, Tool, VertexRagStore, Part
import vertexai
from vertexai import rag

logger = logging.getLogger(__name__)


@dataclass
class MultimodalRAGCorpusConfig:
    """
    üé≠ Configura√ß√£o de um corpus RAG multimodal
    """
    nome: str
    descricao: str
    diretorio_local: str
    bucket_path: str
    tipos_arquivo: List[str]
    tipos_multimodal: List[str] = field(default_factory=list)
    ativo: bool = True
    corpus_id: Optional[str] = None
    suporte_multimodal: bool = True
    
    def __post_init__(self):
        """Configura√ß√µes autom√°ticas ap√≥s inicializa√ß√£o"""
        if not self.tipos_multimodal:
            self.tipos_multimodal = [
                # Imagens
                ".jpg", ".jpeg", ".png", ".gif", ".bmp", ".webp", ".tiff",
                # V√≠deos
                ".mp4", ".avi", ".mov", ".wmv", ".flv", ".webm", ".mkv",
                # √Åudio
                ".mp3", ".wav", ".flac", ".aac", ".ogg", ".m4a"
            ]
    
    def eh_arquivo_multimodal(self, arquivo_path: str) -> bool:
        """Verifica se o arquivo √© multimodal"""
        extensao = Path(arquivo_path).suffix.lower()
        return extensao in self.tipos_multimodal
    
    def eh_arquivo_texto(self, arquivo_path: str) -> bool:
        """Verifica se o arquivo √© de texto/documento"""
        extensao = Path(arquivo_path).suffix.lower()
        return extensao in self.tipos_arquivo
    
    def to_dict(self) -> Dict[str, Any]:
        """
        Converte a configura√ß√£o do corpus RAG multimodal para dicion√°rio
        
        Returns:
            Dicion√°rio com todas as configura√ß√µes do corpus multimodal,
            incluindo tipos de arquivo e configura√ß√µes de m√≠dia
        """
        return {
            'nome': self.nome,
            'descricao': self.descricao,
            'diretorio_local': self.diretorio_local,
            'bucket_path': self.bucket_path,
            'tipos_arquivo': self.tipos_arquivo,
            'tipos_multimodal': self.tipos_multimodal,
            'ativo': self.ativo,
            'suporte_multimodal': self.suporte_multimodal,
            'corpus_id': self.corpus_id
        }


class ProcessadorMultimodal:
    """
    üé® Processador de conte√∫do multimodal
    
    Converte diferentes tipos de m√≠dia para formatos compat√≠veis
    com o Gemini e Vertex AI.
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.tipos_suportados = {
            'imagem': ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.tiff'],
            'video': ['.mp4', '.avi', '.mov', '.wmv', '.flv', '.webm', '.mkv'],
            'audio': ['.mp3', '.wav', '.flac', '.aac', '.ogg', '.m4a'],
            'documento': ['.pdf', '.txt', '.md', '.docx', '.doc', '.rtf']
        }
    
    def detectar_tipo_midia(self, arquivo_path: str) -> str:
        """
        Detecta o tipo de m√≠dia do arquivo
        
        Args:
            arquivo_path: Caminho do arquivo
            
        Returns:
            Tipo de m√≠dia ('imagem', 'video', 'audio', 'documento', 'desconhecido')
        """
        extensao = Path(arquivo_path).suffix.lower()
        
        for tipo, extensoes in self.tipos_suportados.items():
            if extensao in extensoes:
                return tipo
        
        return 'desconhecido'
    
    def processar_imagem(self, arquivo_path: str) -> Part:
        """
        Processa arquivo de imagem para o Gemini
        
        Args:
            arquivo_path: Caminho da imagem
            
        Returns:
            Part do Gemini com a imagem
        """
        try:
            # Detectar MIME type
            mime_type, _ = mimetypes.guess_type(arquivo_path)
            if not mime_type or not mime_type.startswith('image/'):
                mime_type = 'image/jpeg'  # Fallback
            
            # Ler e codificar imagem
            with open(arquivo_path, 'rb') as f:
                image_bytes = f.read()
            
            # Verificar tamanho (limite de 20MB para Gemini)
            tamanho_mb = len(image_bytes) / (1024 * 1024)
            if tamanho_mb > 20:
                raise ValueError(f"Imagem muito grande: {tamanho_mb:.1f}MB (m√°ximo: 20MB)")
            
            # Criar Part
            return Part.from_bytes(
                mime_type=mime_type,
                data=image_bytes
            )
            
        except Exception as e:
            raise RuntimeError(f"Erro ao processar imagem {arquivo_path}: {e}")
    
    def processar_video(self, arquivo_path: str) -> Part:
        """
        Processa arquivo de v√≠deo para o Gemini
        
        Args:
            arquivo_path: Caminho do v√≠deo
            
        Returns:
            Part do Gemini com o v√≠deo
        """
        try:
            # Detectar MIME type
            mime_type, _ = mimetypes.guess_type(arquivo_path)
            if not mime_type or not mime_type.startswith('video/'):
                mime_type = 'video/mp4'  # Fallback
            
            # Ler v√≠deo
            with open(arquivo_path, 'rb') as f:
                video_bytes = f.read()
            
            # Verificar tamanho (limite maior para v√≠deos)
            tamanho_mb = len(video_bytes) / (1024 * 1024)
            limite_mb = self.config.get('limite_video_mb', 100)
            
            if tamanho_mb > limite_mb:
                raise ValueError(f"V√≠deo muito grande: {tamanho_mb:.1f}MB (m√°ximo: {limite_mb}MB)")
            
            # Criar Part
            return Part.from_bytes(
                mime_type=mime_type,
                data=video_bytes
            )
            
        except Exception as e:
            raise RuntimeError(f"Erro ao processar v√≠deo {arquivo_path}: {e}")
    
    def processar_audio(self, arquivo_path: str) -> Part:
        """
        Processa arquivo de √°udio para o Gemini
        
        Args:
            arquivo_path: Caminho do √°udio
            
        Returns:
            Part do Gemini com o √°udio
        """
        try:
            # Detectar MIME type
            mime_type, _ = mimetypes.guess_type(arquivo_path)
            if not mime_type or not mime_type.startswith('audio/'):
                mime_type = 'audio/mpeg'  # Fallback
            
            # Ler √°udio
            with open(arquivo_path, 'rb') as f:
                audio_bytes = f.read()
            
            # Verificar tamanho
            tamanho_mb = len(audio_bytes) / (1024 * 1024)
            limite_mb = self.config.get('limite_audio_mb', 50)
            
            if tamanho_mb > limite_mb:
                raise ValueError(f"√Åudio muito grande: {tamanho_mb:.1f}MB (m√°ximo: {limite_mb}MB)")
            
            # Criar Part
            return Part.from_bytes(
                mime_type=mime_type,
                data=audio_bytes
            )
            
        except Exception as e:
            raise RuntimeError(f"Erro ao processar √°udio {arquivo_path}: {e}")
    
    def extrair_texto_de_midia(self, arquivo_path: str, cliente_ia) -> str:
        """
        Extrai texto/descri√ß√£o de arquivos de m√≠dia usando Gemini Vision
        
        Args:
            arquivo_path: Caminho do arquivo
            cliente_ia: Cliente do Gemini
            
        Returns:
            Texto extra√≠do ou descri√ß√£o da m√≠dia
        """
        tipo_midia = self.detectar_tipo_midia(arquivo_path)
        
        try:
            if tipo_midia == 'imagem':
                return self._extrair_texto_imagem(arquivo_path, cliente_ia)
            elif tipo_midia == 'video':
                return self._extrair_texto_video(arquivo_path, cliente_ia)
            elif tipo_midia == 'audio':
                return self._extrair_texto_audio(arquivo_path, cliente_ia)
            else:
                return f"Arquivo de m√≠dia n√£o suportado: {tipo_midia}"
                
        except Exception as e:
            logger.error(f"Erro ao extrair texto de {arquivo_path}: {e}")
            return f"Erro ao processar arquivo de m√≠dia: {Path(arquivo_path).name}"
    
    def _extrair_texto_imagem(self, arquivo_path: str, cliente_ia) -> str:
        """Extrai texto de imagem usando Gemini Vision"""
        try:
            image_part = self.processar_imagem(arquivo_path)
            
            prompt = """
            Analise esta imagem detalhadamente e forne√ßa:
            
            1. **Descri√ß√£o geral**: O que voc√™ v√™ na imagem
            2. **Texto vis√≠vel**: Qualquer texto, n√∫meros ou dados que aparecem
            3. **Elementos t√©cnicos**: Gr√°ficos, tabelas, diagramas, f√≥rmulas
            4. **Contexto**: Poss√≠vel rela√ß√£o com valida√ß√£o de modelos, riscos, ou an√°lises financeiras
            5. **Informa√ß√µes relevantes**: Dados, m√©tricas, ou insights importantes
            
            Seja detalhado e preciso, pois esta informa√ß√£o ser√° usada para consultas futuras.
            """
            
            resposta = cliente_ia.models.generate_content(
                model=self.config.get('modelo_vision', 'gemini-1.5-pro-002'),
                contents=[image_part, prompt]
            )
            
            return f"IMAGEM: {Path(arquivo_path).name}\n\n{resposta.text}"
            
        except Exception as e:
            return f"Erro ao analisar imagem {Path(arquivo_path).name}: {e}"
    
    def _extrair_texto_video(self, arquivo_path: str, cliente_ia) -> str:
        """Extrai informa√ß√µes de v√≠deo usando Gemini"""
        try:
            video_part = self.processar_video(arquivo_path)
            
            prompt = """
            Analise este v√≠deo e forne√ßa:
            
            1. **Resumo do conte√∫do**: O que acontece no v√≠deo
            2. **Texto vis√≠vel**: Qualquer texto, slides, ou dados mostrados
            3. **√Åudio/Narra√ß√£o**: Principais pontos falados (se houver)
            4. **Elementos visuais**: Gr√°ficos, apresenta√ß√µes, demonstra√ß√µes
            5. **Contexto t√©cnico**: Rela√ß√£o com modelos, valida√ß√£o, ou an√°lises
            6. **Momentos importantes**: Timestamps de informa√ß√µes relevantes
            
            Foque em informa√ß√µes que seriam √∫teis para consultas sobre valida√ß√£o de modelos.
            """
            
            resposta = cliente_ia.models.generate_content(
                model=self.config.get('modelo_vision', 'gemini-1.5-pro-002'),
                contents=[video_part, prompt]
            )
            
            return f"V√çDEO: {Path(arquivo_path).name}\n\n{resposta.text}"
            
        except Exception as e:
            return f"Erro ao analisar v√≠deo {Path(arquivo_path).name}: {e}"
    
    def _extrair_texto_audio(self, arquivo_path: str, cliente_ia) -> str:
        """Extrai texto de √°udio usando Gemini"""
        try:
            audio_part = self.processar_audio(arquivo_path)
            
            prompt = """
            Analise este √°udio e forne√ßa:
            
            1. **Transcri√ß√£o**: Texto falado no √°udio (se poss√≠vel)
            2. **Resumo do conte√∫do**: Principais t√≥picos abordados
            3. **Contexto**: Tipo de apresenta√ß√£o, reuni√£o, ou explica√ß√£o
            4. **Informa√ß√µes t√©cnicas**: Dados, m√©tricas, ou conceitos mencionados
            5. **Pontos importantes**: Insights relevantes para valida√ß√£o de modelos
            
            Seja preciso na transcri√ß√£o e identifique informa√ß√µes t√©cnicas importantes.
            """
            
            resposta = cliente_ia.models.generate_content(
                model=self.config.get('modelo_vision', 'gemini-1.5-pro-002'),
                contents=[audio_part, prompt]
            )
            
            return f"√ÅUDIO: {Path(arquivo_path).name}\n\n{resposta.text}"
            
        except Exception as e:
            return f"Erro ao analisar √°udio {Path(arquivo_path).name}: {e}"


class ValidAIRAGMultimodal:
    """
    üé≠ Sistema RAG Multimodal para ValidAI
    
    Extens√£o do sistema RAG que suporta documentos, imagens, v√≠deos
    e outros tipos de m√≠dia usando Gemini Vision e Vertex AI.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Inicializa o sistema RAG multimodal
        
        Args:
            config: Configura√ß√µes do sistema
        """
        self.config = config
        self.corpus_configs: Dict[str, MultimodalRAGCorpusConfig] = {}
        self.corpus_ativos: Dict[str, Any] = {}
        self.ferramentas_busca: Dict[str, Tool] = {}
        
        # Inicializar processador multimodal
        self.processador_multimodal = ProcessadorMultimodal(config)
        
        # Inicializar Google Cloud
        self._inicializar_google_cloud()
        
        # Carregar configura√ß√µes de corpus
        self._carregar_configuracoes_corpus()
        
        logger.info("‚úÖ ValidAI RAG Multimodal inicializado")
    
    def _inicializar_google_cloud(self) -> None:
        """Inicializa conex√µes com Google Cloud"""
        try:
            logger.info("üîó Conectando com Google Cloud...")
            
            vertexai.init(
                project=self.config['project_id'],
                location=self.config['location']
            )
            
            self.cliente_ia = genai.Client(
                vertexai=True,
                project=self.config['project_id'],
                location=self.config['location']
            )
            
            self.cliente_storage = storage.Client(
                project=self.config['project_id']
            )
            
            logger.info("‚úÖ Conectado ao Google Cloud")
            
        except Exception as e:
            raise RuntimeError(f"‚ùå Erro na conex√£o Google Cloud: {e}")
    
    def _carregar_configuracoes_corpus(self) -> None:
        """Carrega configura√ß√µes dos corpus multimodais"""
        logger.info("üìã Carregando configura√ß√µes de corpus multimodais...")
        
        # Configura√ß√µes padr√£o com suporte multimodal
        corpus_padrao = {
            'instrucoes_normativas': MultimodalRAGCorpusConfig(
                nome="Instru√ß√µes Normativas",
                descricao="INs 706, 1253 e 1146 com imagens e diagramas",
                diretorio_local="base_conhecimento/ins",
                bucket_path="validai-rag/ins",
                tipos_arquivo=[".pdf", ".txt", ".md"],
                suporte_multimodal=True
            ),
            'apresentacoes_validacao': MultimodalRAGCorpusConfig(
                nome="Apresenta√ß√µes e V√≠deos",
                descricao="Apresenta√ß√µes, v√≠deos explicativos e materiais visuais",
                diretorio_local="base_conhecimento/apresentacoes",
                bucket_path="validai-rag/apresentacoes",
                tipos_arquivo=[".pdf", ".pptx", ".txt", ".md"],
                suporte_multimodal=True
            ),
            'graficos_metricas': MultimodalRAGCorpusConfig(
                nome="Gr√°ficos e M√©tricas",
                descricao="Visualiza√ß√µes, dashboards e gr√°ficos de performance",
                diretorio_local="base_conhecimento/graficos",
                bucket_path="validai-rag/graficos",
                tipos_arquivo=[".pdf", ".txt", ".md"],
                suporte_multimodal=True
            ),
            'casos_uso_visuais': MultimodalRAGCorpusConfig(
                nome="Casos de Uso Visuais",
                descricao="Exemplos pr√°ticos com imagens, v√≠deos e demonstra√ß√µes",
                diretorio_local="base_conhecimento/casos_visuais",
                bucket_path="validai-rag/casos_visuais",
                tipos_arquivo=[".pdf", ".txt", ".md", ".ipynb"],
                suporte_multimodal=True
            )
        }
        
        # Carregar configura√ß√µes personalizadas
        config_file = self.config.get('corpus_config_file', 'rag_multimodal_config.json')
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                
                for nome, data in config_data.items():
                    corpus_padrao[nome] = MultimodalRAGCorpusConfig(**data)
                
                logger.info(f"‚úÖ Configura√ß√µes carregadas de {config_file}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao carregar config: {e}")
        
        self.corpus_configs = corpus_padrao
        logger.info(f"üìã {len(self.corpus_configs)} corpus multimodais configurados")
    
    def processar_arquivos_multimodais(self, corpus_id: str) -> Dict[str, Any]:
        """
        Processa arquivos multimodais de um corpus
        
        Args:
            corpus_id: ID do corpus
            
        Returns:
            Estat√≠sticas do processamento
        """
        if corpus_id not in self.corpus_configs:
            raise ValueError(f"Corpus n√£o encontrado: {corpus_id}")
        
        config = self.corpus_configs[corpus_id]
        diretorio = Path(config.diretorio_local)
        
        if not diretorio.exists():
            raise ValueError(f"Diret√≥rio n√£o existe: {diretorio}")
        
        logger.info(f"üé≠ Processando arquivos multimodais: {config.nome}")
        
        estatisticas = {
            'total_arquivos': 0,
            'arquivos_texto': 0,
            'arquivos_imagem': 0,
            'arquivos_video': 0,
            'arquivos_audio': 0,
            'arquivos_processados': 0,
            'erros': 0,
            'textos_extraidos': []
        }
        
        # Processar todos os arquivos
        for arquivo in diretorio.rglob('*'):
            if arquivo.is_file():
                estatisticas['total_arquivos'] += 1
                
                try:
                    if config.eh_arquivo_texto(str(arquivo)):
                        # Arquivo de texto normal
                        estatisticas['arquivos_texto'] += 1
                        estatisticas['arquivos_processados'] += 1
                        
                    elif config.eh_arquivo_multimodal(str(arquivo)):
                        # Arquivo multimodal - extrair texto
                        tipo_midia = self.processador_multimodal.detectar_tipo_midia(str(arquivo))
                        
                        if tipo_midia == 'imagem':
                            estatisticas['arquivos_imagem'] += 1
                        elif tipo_midia == 'video':
                            estatisticas['arquivos_video'] += 1
                        elif tipo_midia == 'audio':
                            estatisticas['arquivos_audio'] += 1
                        
                        # Extrair texto da m√≠dia
                        texto_extraido = self.processador_multimodal.extrair_texto_de_midia(
                            str(arquivo), self.cliente_ia
                        )
                        
                        estatisticas['textos_extraidos'].append({
                            'arquivo': str(arquivo),
                            'tipo': tipo_midia,
                            'texto': texto_extraido
                        })
                        
                        estatisticas['arquivos_processados'] += 1
                        
                        logger.info(f"   üé® Processado {tipo_midia}: {arquivo.name}")
                
                except Exception as e:
                    logger.error(f"‚ùå Erro ao processar {arquivo.name}: {e}")
                    estatisticas['erros'] += 1
        
        logger.info(f"‚úÖ Processamento conclu√≠do: {estatisticas['arquivos_processados']} arquivos")
        return estatisticas
    
    def consultar_multimodal(self, corpus_id: str, pergunta: str, 
                           incluir_contexto_visual: bool = True) -> str:
        """
        Faz consulta multimodal incluindo contexto de imagens/v√≠deos
        
        Args:
            corpus_id: ID do corpus
            pergunta: Pergunta do usu√°rio
            incluir_contexto_visual: Se deve incluir contexto de m√≠dias
            
        Returns:
            Resposta da IA com contexto multimodal
        """
        if corpus_id not in self.ferramentas_busca:
            raise ValueError(f"Ferramenta de busca n√£o dispon√≠vel para: {corpus_id}")
        
        ferramenta = self.ferramentas_busca[corpus_id]
        config = self.corpus_configs[corpus_id]
        
        logger.info(f"üé≠ Consulta multimodal em {config.nome}: {pergunta[:50]}...")
        
        try:
            # Criar prompt contextualizado para multimodal
            prompt_base = f"""
            Voc√™ est√° consultando a base de conhecimento multimodal: {config.nome}
            Descri√ß√£o: {config.descricao}
            
            Esta base cont√©m documentos, imagens, v√≠deos e outros tipos de m√≠dia.
            Quando relevante, fa√ßa refer√™ncia a informa√ß√µes visuais, gr√°ficos, ou 
            conte√∫do extra√≠do de m√≠dias.
            
            Pergunta do usu√°rio: {pergunta}
            """
            
            if incluir_contexto_visual:
                prompt_base += """
                
                IMPORTANTE: Se houver informa√ß√µes visuais relevantes (gr√°ficos, imagens, 
                v√≠deos, apresenta√ß√µes), inclua essas informa√ß√µes na sua resposta e 
                mencione especificamente quando estiver se referindo a conte√∫do visual.
                """
            
            resposta = self.cliente_ia.models.generate_content(
                model=self.config.get('modelo_ia', 'gemini-1.5-pro-002'),
                contents=prompt_base,
                config=GenerateContentConfig(tools=[ferramenta]),
            )
            
            return resposta.text
            
        except Exception as e:
            raise RuntimeError(f"‚ùå Erro na consulta multimodal: {e}")
    
    def salvar_textos_extraidos(self, corpus_id: str, estatisticas: Dict[str, Any]) -> str:
        """
        Salva textos extra√≠dos de m√≠dias em arquivo para refer√™ncia
        
        Args:
            corpus_id: ID do corpus
            estatisticas: Estat√≠sticas do processamento
            
        Returns:
            Caminho do arquivo salvo
        """
        config = self.corpus_configs[corpus_id]
        
        # Criar arquivo de textos extra√≠dos
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        arquivo_saida = Path(config.diretorio_local) / f"textos_extraidos_{timestamp}.md"
        
        conteudo = f"""# Textos Extra√≠dos - {config.nome}

Gerado em: {datetime.now().isoformat()}
Corpus: {corpus_id}

## Estat√≠sticas
- Total de arquivos: {estatisticas['total_arquivos']}
- Arquivos de texto: {estatisticas['arquivos_texto']}
- Imagens processadas: {estatisticas['arquivos_imagem']}
- V√≠deos processados: {estatisticas['arquivos_video']}
- √Åudios processados: {estatisticas['arquivos_audio']}
- Erros: {estatisticas['erros']}

## Conte√∫do Extra√≠do

"""
        
        for item in estatisticas['textos_extraidos']:
            conteudo += f"""
### {item['arquivo']} ({item['tipo'].upper()})

{item['texto']}

---

"""
        
        # Salvar arquivo
        with open(arquivo_saida, 'w', encoding='utf-8') as f:
            f.write(conteudo)
        
        logger.info(f"üíæ Textos extra√≠dos salvos em: {arquivo_saida}")
        return str(arquivo_saida)


def criar_configuracao_rag_multimodal() -> Dict[str, Any]:
    """
    Cria configura√ß√£o padr√£o para o sistema RAG multimodal
    
    Returns:
        Dicion√°rio de configura√ß√£o
    """
    config_base = {
        'project_id': 'bv-cdip-des',
        'location': 'us-central1',
        'bucket_name': 'validai-rag-multimodal',
        'modelo_embedding': 'publishers/google/models/text-embedding-005',
        'modelo_ia': 'gemini-1.5-pro-002',
        'modelo_vision': 'gemini-1.5-pro-002',
        'chunk_size': 1024,
        'chunk_overlap': 256,
        'top_resultados': 10,
        'limite_similaridade': 0.5,
        'tamanho_max_arquivo_mb': 50,
        'limite_video_mb': 100,
        'limite_audio_mb': 50,
        'corpus_config_file': 'rag_multimodal_config.json'
    }
    
    return config_base


# Exemplo de uso
if __name__ == "__main__":
    # Configura√ß√£o multimodal
    config = criar_configuracao_rag_multimodal()
    
    # Inicializar sistema RAG multimodal
    rag_multimodal = ValidAIRAGMultimodal(config)
    
    # Listar corpus dispon√≠veis
    print("üé≠ Corpus multimodais dispon√≠veis:")
    for corpus_id, config in rag_multimodal.corpus_configs.items():
        print(f"  - {config.nome} ({corpus_id})")
        print(f"    Suporte multimodal: {config.suporte_multimodal}")
        print(f"    Tipos: {config.tipos_arquivo + config.tipos_multimodal}")